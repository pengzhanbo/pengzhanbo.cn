import{_ as i,c as a,a as n,o as t}from"./app-CswOyyIB.js";const h={};function e(l,s){return t(),a("div",null,[...s[0]||(s[0]=[n(`<p>如果你和大模型聊过天（比如 GPT-4），你可能特别佩服它那种信手拈来的知识和妙语连珠的能力。但说实话，你可能也坑过——它会正儿八经地瞎扯（我们叫它“幻觉”），或压根不知道昨天发生了啥新闻。</p><p>这就像是你有个极其博学的“神经病最强大脑”，但他的记忆最后更新时间定格在好几年前。</p><p>那么问题来了，有没有办法让这颗脑袋不仅能查内存，还能实时联网查外部资料？特别是能访问我们自己的私人数据？</p><p>有没有这么一把钥匙？有，它就是 <strong>RAG</strong>，全名 <strong>Retrieval-Augmented Generation</strong>，翻译过来就是“检索增强生成”。</p><h2 id="一、说人话-rag-到底是啥-为啥这么重要" tabindex="-1"><a class="header-anchor" href="#一、说人话-rag-到底是啥-为啥这么重要"><span>一、说人话，RAG 到底是啥？为啥这么重要？</span></a></h2><p>你可以把 RAG 理解成给大模型配了个 “贴身外挂+图书馆管理员”：</p><blockquote><p>它让 LLM（也就是那些大模型）不再只能靠自己的静态知识输出内容，而是允许它去一个“指定的知识库”里开卷考试！</p></blockquote><p>比如你问：</p><div class="language-txt" data-highlighter="shiki" data-ext="txt" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-txt"><span class="line"><span>“AI 最近出啥新鲜事了？”</span></span></code></pre></div><p>普通 LLM 会说：</p><div class="language-txt" data-highlighter="shiki" data-ext="txt" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-txt"><span class="line"><span>“抱歉啦，我学到的知识截止到 2024 年秋天，实在不清楚你讲的是不是今天的新闻。”</span></span></code></pre></div><p>人家是真的不知道。</p><p><strong>RAG 的出现，就是来解决两个痛点：</strong></p><ol><li><strong>知识会过期</strong>：LLM 学的知识一旦训练完就“封印”了。</li><li><strong>你私人的东西它看不到</strong>：公司内部文档、个人笔记它无从知晓。</li></ol><p>而 RAG 是这么做的：</p><div class="language-txt" data-highlighter="shiki" data-ext="txt" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-txt"><span class="line"><span>“你问，等一下，我去查手册。”</span></span></code></pre></div><p>这就意味着你的 AI 不再只是个背书的学霸，而是一个可以现场翻资料的“活字典+智能分析师”。</p><h2 id="二、rag-的核心原理-三步走-不复杂" tabindex="-1"><a class="header-anchor" href="#二、rag-的核心原理-三步走-不复杂"><span>二、RAG 的核心原理：三步走，不复杂</span></a></h2><p>用一句话总结 RAG 就是：</p><div class="hint-container tip"><p class="hint-container-title">先查资料，再生成答案。</p></div><p>整个流程拆开一看其实非常清晰：</p><h3 id="🧾-第一步-索引阶段-indexing-——先准备好你的资料库" tabindex="-1"><a class="header-anchor" href="#🧾-第一步-索引阶段-indexing-——先准备好你的资料库"><span>🧾 第一步：索引阶段（Indexing）——先准备好你的资料库</span></a></h3><p>这部分是在回答用户提问前就已经搞好的。</p><p>想象你要做个《哈利波特》问答机器人：</p><ol><li><strong>加载文档</strong>：把整本书或者网页资源读进来。</li><li><strong>切割文档</strong>：太大了不好处理，要分成一段一段的“chunks”。</li><li><strong>向量化处理</strong>：每段都被转换为数学向量（这就是所谓的 Embedding）。</li><li><strong>存进数据库</strong>：用这些向量建立一张“知识地图”，保存到类似 FAISS、Chroma 这样的向量数据库中。</li></ol><p>这步做完，你的“图书室 + 搜索引擎”就已经建好了。</p><h3 id="🔍-第二步-检索阶段-retrieval-——用户问问题时去快速查找" tabindex="-1"><a class="header-anchor" href="#🔍-第二步-检索阶段-retrieval-——用户问问题时去快速查找"><span>🔍 第二步：检索阶段（Retrieval）——用户问问题时去快速查找</span></a></h3><p>假设你现在问 AI：</p><div class="language-txt" data-highlighter="shiki" data-ext="txt" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-txt"><span class="line"><span>“火焰杯大赛里魔法部派谁来看哈利？”</span></span></code></pre></div><p>系统这时候会：</p><ol><li>把你这句话向量化；</li><li>在刚才打造的那个“知识地图”中搜索最匹配的几个段落；</li><li>把这些相关段落抓出来作为“参考资料”。</li></ol><p>于是你在这一阶段已经拿到了和问题最贴切的内容。</p><h3 id="💬-第三步-增强与生成阶段-augmented-generation-——带着参考资料一起来生成结果" tabindex="-1"><a class="header-anchor" href="#💬-第三步-增强与生成阶段-augmented-generation-——带着参考资料一起来生成结果"><span>💬 第三步：增强与生成阶段（Augmented Generation）——带着参考资料一起来生成结果</span></a></h3><p>最后一步，才是真正的“创作”：</p><ol><li>把你原始问题和刚查到的数据打包成一段提示（Prompt）；</li><li>交给大模型（如 GPT、Llama 等）进行“打分并整合生成”。</li></ol><p>比如：</p><div class="language-bash" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">请根据以下内容做出解释：</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">【背景信息】</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">-</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> 在火焰杯期间，魔法部派遣了一支强制执行队维持赛场秩序，由巴格曼担任总指挥。</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">【用户问题】</span></span>
<span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">火焰杯比赛中魔法部支持了哪些措施？</span></span></code></pre></div><p>最终输出就会告诉你：魔法部安排了强制执行队、任命巴格曼为负责人……</p><p>这就像是做了场高质量的“开卷考试”。</p><h2 id="三、动手实战一下-教你怎么搭个-rag-应用玩一玩" tabindex="-1"><a class="header-anchor" href="#三、动手实战一下-教你怎么搭个-rag-应用玩一玩"><span>三、动手实战一下？教你怎么搭个 RAG 应用玩一玩</span></a></h2><p>我们用 <a href="https://python.langchain.com/docs/get_started/introduction" target="_blank" rel="noopener noreferrer">LangChain</a> 搭一个小型的“网页情报助手”。</p><h3 id="🔧-准备工作——先安装工具" tabindex="-1"><a class="header-anchor" href="#🔧-准备工作——先安装工具"><span>🔧 准备工作——先安装工具</span></a></h3><div class="language-bash" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#59873A;--shiki-dark:#80A665;">pip</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> install</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> langchain</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> langchain-openai</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> langchain-community</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> faiss-cpu</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> beautifulsoup4</span></span></code></pre></div><p>几个组件它们分别干嘛你知道就行：</p><ul><li>LangChain：串联流程</li><li>WebBaseLoader：抓网页 ↓ 页面 → 文本</li><li>recursiveCharacterTextSplitter：自动分句+切块</li><li>OpenAIEmbeddings + FAISS：生成 + 保存向量库</li><li>ChatOpenAI：驱动聊天的 guy</li></ul><p>然后设好 API KEY，通常这样：</p><div class="language-bash" data-highlighter="shiki" data-ext="bash" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-bash"><span class="line"><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">export</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> OPENAI_API_KEY</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&#39;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">xxx</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&#39;</span></span></code></pre></div><h3 id="🧾-step-1-加载网页并切块" tabindex="-1"><a class="header-anchor" href="#🧾-step-1-加载网页并切块"><span>🧾 Step 1：加载网页并切块</span></a></h3><div class="language-python" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">from</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> langchain_community</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">document_loaders </span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">import</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> WebBaseLoader</span></span>
<span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">from</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> langchain_text_splitters </span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">import</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> RecursiveCharacterTextSplitter</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">loader </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> WebBaseLoader</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">https://your-target-page.com</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">docs </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> loader</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">load</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">text_splitter </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> RecursiveCharacterTextSplitter</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;">chunk_size</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">500</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> chunk_overlap</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#2F798A;--shiki-dark:#4C9A91;">0</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">splits </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> text_splitter</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">split_documents</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">docs</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">print</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#AB5959;--shiki-dark:#CB7676;">f</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">&quot;已切出 </span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">{</span><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">len</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">splits</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">}</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;"> 个小块。&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span></code></pre></div><h3 id="📦-step-2-向量化存储" tabindex="-1"><a class="header-anchor" href="#📦-step-2-向量化存储"><span>📦 Step 2：向量化存储</span></a></h3><div class="language-python" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">from</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> langchain_openai </span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">import</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> OpenAIEmbeddings</span></span>
<span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">from</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> langchain_community</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">vectorstores </span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">import</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> FAISS</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">embedding </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> OpenAIEmbeddings</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">()</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">vectorstore </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;"> FAISS</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">from_documents</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;">documents</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">splits</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;"> embedding</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">embedding</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">print</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">✅ 向量库创建成功</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span></code></pre></div><h3 id="⚡️-step-3-构建问答链" tabindex="-1"><a class="header-anchor" href="#⚡️-step-3-构建问答链"><span>⚡️ Step 3：构建问答链</span></a></h3><div class="language-python line-numbers-mode" data-highlighter="shiki" data-ext="python" style="--shiki-light:#393a34;--shiki-dark:#dbd7caee;--shiki-light-bg:#ffffff;--shiki-dark-bg:#121212;"><pre class="shiki shiki-themes vitesse-light vitesse-dark vp-code"><code class="language-python"><span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">from</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> langchain_openai </span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">import</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> ChatOpenAI</span></span>
<span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">from</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> langchain_core</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">prompts </span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">import</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> ChatPromptTemplate</span></span>
<span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">from</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> langchain</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">chains </span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">import</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> create_retrieval_chain</span></span>
<span class="line"><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">from</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> langchain</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">chains</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">combine_documents </span><span style="--shiki-light:#1E754F;--shiki-dark:#4D9375;">import</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> create_stuff_documents_chain</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">llm </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> ChatOpenAI</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#B07D48;--shiki-dark:#BD976A;">model</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">gpt-3.5-turbo</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">retriever </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> vectorstore</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">as_retriever</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">()</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">prompt </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> ChatPromptTemplate</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">from_template</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;&quot;&quot;</span></span>
<span class="line"><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">Answer the question using only the provided context:</span></span>
<span class="line"><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">&lt;context&gt;</span></span>
<span class="line"><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">{context}</span></span>
<span class="line"><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">&lt;/context&gt;</span></span>
<span class="line"><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">Question: </span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">{input}</span></span>
<span class="line"><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;&quot;&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">document_chain </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> create_stuff_documents_chain</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">llm</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> prompt</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">retrieval_chain </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> create_retrieval_chain</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">retriever</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> document_chain</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">)</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#A0ADA0;--shiki-dark:#758575DD;"># 最后调用一下看看</span></span>
<span class="line"><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">response </span><span style="--shiki-light:#999999;--shiki-dark:#666666;">=</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> retrieval_chain</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">.</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;">invoke</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">({</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">input</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">:</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;"> &quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">What did the article say about RAG?</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">})</span></span>
<span class="line"><span style="--shiki-light:#998418;--shiki-dark:#B8A965;">print</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">(</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">\\n</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">---Answer---</span><span style="--shiki-light:#A65E2B;--shiki-dark:#C99076;">\\n</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">,</span><span style="--shiki-light:#393A34;--shiki-dark:#DBD7CAEE;"> response</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">[</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#B56959;--shiki-dark:#C98A7D;">answer</span><span style="--shiki-light:#B5695977;--shiki-dark:#C98A7D77;">&quot;</span><span style="--shiki-light:#999999;--shiki-dark:#666666;">])</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>这样你就做出了一个小小的基于实时网页内容的 QA bot！</p><h2 id="四、rag-的优势和小烦恼" tabindex="-1"><a class="header-anchor" href="#四、rag-的优势和小烦恼"><span>四、RAG 的优势和小烦恼</span></a></h2><h3 id="✅-它的好处太明显了" tabindex="-1"><a class="header-anchor" href="#✅-它的好处太明显了"><span>✅ 它的好处太明显了</span></a></h3><ul><li><strong>能防幻觉你知道吧？</strong> 答案基于真的信息，而不是大模型随便编。</li><li><strong>旧数据也能“续命”</strong> 你不需要反复训练模型，只要更新外部数据库就行。</li><li><strong>私密内容用得上</strong> 公司机密？内部 Wiki？它就只从这里头查，其他人谁也看不见。</li><li><strong>成本可控</strong> 不用继续烧 GPU 微调模型，维护个知识库快多了。</li></ul><h3 id="⚠️-当然也有挑战" tabindex="-1"><a class="header-anchor" href="#⚠️-当然也有挑战"><span>⚠️ 当然也有挑战</span></a></h3><ul><li><strong>查得准才是关键</strong> 查错了或者查不到，直接 GG。</li><li><strong>多文档整合麻烦</strong> 文档彼此矛盾怎么办？AI 怎么知道谁说的是真的？</li><li><strong>大库检索太慢？</strong> 如果文档有百万数量级，光查也要几秒……太影响体验。</li></ul><h2 id="五、未来-更高阶玩法在哪" tabindex="-1"><a class="header-anchor" href="#五、未来-更高阶玩法在哪"><span>五、未来：更高阶玩法在哪？</span></a></h2><p>其实今天我们聊的算是“标准版 RAG”，现在已经有不少进化版本，比如：</p><table><thead><tr><th>类型</th><th>核心升级点</th></tr></thead><tbody><tr><td>Hybrid RAG</td><td>结合关键词检索 + 语义相似度（提升查准率）</td></tr><tr><td>Query Rewriting/Routing</td><td>先改写问题，再分发给不同类型的知识集合</td></tr><tr><td>MemoRAG</td><td>加上了长期记忆，记住以前对话中的信息</td></tr><tr><td>GraphRAG</td><td>把知识结构图化处理，适合逻辑推理</td></tr></tbody></table><div class="hint-container tip"><p class="hint-container-title">提一句</p><p>现在很多头部企业在搭建的所谓的 AI Agent 系统背后，基本都藏着一套定制化的 RAG 流程。你以为它秒回那么专业？它其实只是查书太快了 😄</p></div><h2 id="六、结语" tabindex="-1"><a class="header-anchor" href="#六、结语"><span>六、结语</span></a></h2><p>总而言之，<strong>RAG 是目前把 LLM 变得实际可落地的重要桥梁之一</strong>。</p><p>它不仅让机器“看得见真实世界的数据”，还允许它在生成响应的过程中灵活调用它们——不再瞎猜，而是有理有据、即插即用。</p><p>未来不管你是做客服系统、法律助手、写作助理，还是你想训练自己专属的知识库，RAG 都是一个绕不开的技术选择。</p><p><strong>推荐你动手试试，别光看文章，代码敲起来才能掌握真本领～</strong></p><h2 id="参考资料" tabindex="-1"><a class="header-anchor" href="#参考资料"><span>参考资料</span></a></h2><ul><li><a href="https://python.langchain.com/docs/get_started/introduction" target="_blank" rel="noopener noreferrer">LangChain 官网文档</a></li><li><a href="https://github.com/facebookresearch/faiss" target="_blank" rel="noopener noreferrer">FAISS 官网介绍</a></li><li><a href="https://platform.openai.com/docs/introduction" target="_blank" rel="noopener noreferrer">OpenAI API 文档</a></li><li><a href="https://huggingface.co/docs/transformers/model_doc/rag" target="_blank" rel="noopener noreferrer">HuggingFace RAG 介绍</a></li><li><a href="https://arxiv.org/abs/2005.11401" target="_blank" rel="noopener noreferrer">原始论文：Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks</a></li></ul>`,70)])])}const k=i(h,[["render",e]]),r=JSON.parse('{"path":"/article/rdx1yx85/","title":"一文读懂 RAG (检索增强生成) | 博客","lang":"zh-CN","frontmatter":{"title":"一文读懂 RAG (检索增强生成)","createTime":"2025/11/19 10:30:14","permalink":"/article/rdx1yx85/","tags":["AI","python"],"description":"如果你和大模型聊过天（比如 GPT-4），你可能特别佩服它那种信手拈来的知识和妙语连珠的能力。但说实话，你可能也坑过——它会正儿八经地瞎扯（我们叫它“幻觉”），或压根不知道昨天发生了啥新闻。 这就像是你有个极其博学的“神经病最强大脑”，但他的记忆最后更新时间定格在好几年前。 那么问题来了，有没有办法让这颗脑袋不仅能查内存，还能实时联网查外部资料？特别是...","head":[["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"一文读懂 RAG (检索增强生成)\\",\\"image\\":[\\"\\"],\\"dateModified\\":\\"2026-01-04T12:47:10.000Z\\",\\"author\\":[]}"],["meta",{"property":"og:url","content":"https://pengzhanbo.cn/article/rdx1yx85/"}],["meta",{"property":"og:site_name","content":"鹏展博"}],["meta",{"property":"og:title","content":"一文读懂 RAG (检索增强生成)"}],["meta",{"property":"og:description","content":"如果你和大模型聊过天（比如 GPT-4），你可能特别佩服它那种信手拈来的知识和妙语连珠的能力。但说实话，你可能也坑过——它会正儿八经地瞎扯（我们叫它“幻觉”），或压根不知道昨天发生了啥新闻。 这就像是你有个极其博学的“神经病最强大脑”，但他的记忆最后更新时间定格在好几年前。 那么问题来了，有没有办法让这颗脑袋不仅能查内存，还能实时联网查外部资料？特别是..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2026-01-04T12:47:10.000Z"}],["meta",{"property":"article:tag","content":"python"}],["meta",{"property":"article:tag","content":"AI"}],["meta",{"property":"article:modified_time","content":"2026-01-04T12:47:10.000Z"}]]},"readingTime":{"minutes":6.24,"words":1872},"git":{"createdTime":1763570632000,"updatedTime":1767530830000,"contributors":[{"name":"pengzhanbo","username":"pengzhanbo","email":"volodymyr@foxmail.com","commits":4,"avatar":"https://avatars.githubusercontent.com/pengzhanbo?v=4","url":"https://github.com/pengzhanbo"}]},"autoDesc":true,"filePathRelative":"blog/4.AI/一文读懂 RAG.md","headers":[],"categoryList":[{"id":"0207b0","sort":4,"name":"AI"}]}');export{k as comp,r as data};
