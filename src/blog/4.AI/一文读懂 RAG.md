---
title: ä¸€æ–‡è¯»æ‡‚ RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ)
createTime: 2025/11/19 10:30:14
permalink: /article/rdx1yx85/
tags:
  - AI
  - python
---

ä½ è‚¯å®šç©è¿‡ ChatGPT è¿™ç±»å¤§æ¨¡å‹å§ï¼Ÿå®ƒä»¬ç¡®å®ç‰›ï¼Œä¸ŠçŸ¥å¤©æ–‡ä¸‹çŸ¥åœ°ç†ï¼Œå†™ä»£ç ã€è‚æ–‡æ¡ˆï¼Œå¥½åƒæ— æ‰€ä¸èƒ½ã€‚ä½†ä½ ä¹Ÿä¸€å®šé‡åˆ°è¿‡è¿™äº›è®©äººå“­ç¬‘ä¸å¾—çš„ç¬é—´ï¼š

- é—®å®ƒä¸ªæ–°é²œå‡ºç‚‰çš„çƒ­ç‚¹æ–°é—»ï¼Œå®ƒæ…¢æ‚ æ‚ åœ°å›ä½ ï¼šâ€œä¸å¥½æ„æ€ï¼Œæˆ‘çš„çŸ¥è¯†åº“åªæ›´æ–°åˆ° 2023 å¹´å“¦ã€‚â€
- æ‰”ç»™å®ƒä¸€ä»½å…¬å¸å†…éƒ¨æŠ¥å‘Šï¼Œè®©å®ƒåšä¸ªæ€»ç»“ï¼Œç»“æœå®ƒè„‘æ´å¤§å¼€ï¼Œç¼–å¾—æœ‰é¼»å­æœ‰çœ¼ï¼Œå°±æ˜¯æ²¡ä¸€å¥åœ¨ç‚¹å­ä¸Šâ€”â€”è¿™å°±æ˜¯æˆ‘ä»¬å¸¸è¯´çš„â€œå¹»è§‰â€ã€‚

è¯´ç™½äº†ï¼Œé—®é¢˜å‡ºåœ¨å“ªå„¿å‘¢ï¼Ÿå¤§æ¨¡å‹å°±åƒä¸ªè®°å¿†åŠ›è¶…ç¾¤ä½†å­¦å®Œå°±ä¸å†æ›´æ–°çš„å­¦éœ¸ï¼ŒçŸ¥è¯†å…¨é â€œèƒŒå¤šåˆ†â€ï¼Œè¢«é”æ­»åœ¨äº†è®­ç»ƒçš„é‚£ä¸€åˆ»ã€‚

é‚£ä¹ˆï¼Œæœ‰æ²¡æœ‰åŠæ³•ç»™è¿™ä¸ªå­¦éœ¸é…ä¸€æœ¬èƒ½éšæ—¶æ›´æ–°çš„â€œå°æŠ„â€ï¼Œè®©å®ƒæ—¢èƒ½ä¿æŒèªæ˜çš„è„‘ç“œï¼Œåˆèƒ½èŠæœ€æ–°çš„è¯é¢˜ã€æ‡‚æˆ‘ä»¬çš„å°ç§˜å¯†ï¼ˆæ¯”å¦‚å…¬å¸å†…éƒ¨æ–‡æ¡£ï¼‰å‘¢ï¼Ÿ

å½“ç„¶æœ‰ï¼è¿™å°±è¦è¯·å‡ºæˆ‘ä»¬ä»Šå¤©çš„ä¸»è§’â€”â€”**æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRetrieval-Augmented Generationï¼Œç®€ç§° RAGï¼‰**ã€‚

## ä¸€ã€ç»™ AI ä¸€åœºâ€œå¼€å·è€ƒè¯•â€ï¼ŒRAG åˆ°åº•æ˜¯ä»€ä¹ˆï¼Ÿ

æƒ³è±¡ä¸€ä¸‹ï¼Œä½ æ˜¯ä¸ªå­¦ç”Ÿï¼Œé¢å¯¹ä¸€åœºé‡è¦çš„è€ƒè¯•ã€‚

- **ä¼ ç»Ÿå¤§æ¨¡å‹ï¼š** çº¯é â€œé—­å·è€ƒâ€ã€‚ä½ åªèƒ½ç”¨è„‘è¢‹é‡Œè®°ä½çš„ä¸œè¥¿ç­”é¢˜ã€‚é‡åˆ°æ²¡èƒŒè¿‡çš„çŸ¥è¯†ç‚¹ï¼Œè¦ä¹ˆäº¤ç™½å·ï¼Œè¦ä¹ˆåªèƒ½å‡­æ„Ÿè§‰çè’™ä¸€ä¸ªï¼ˆä¹Ÿå°±æ˜¯æ¨¡å‹çš„â€œå¹»è§‰â€ï¼‰ã€‚
- **RAGï¼š** å°±åƒç›‘è€ƒè€å¸ˆçªç„¶å‘å–„å¿ƒï¼Œç»™äº†ä½ ä¸€æœ¬æƒå¨å‚è€ƒä¹¦ï¼Œè®©ä½ â€œå¼€å·è€ƒâ€ï¼é‡åˆ°ä¸ä¼šçš„é¢˜ï¼Œä½ ä¸å†éœ€è¦ççŒœï¼Œè€Œæ˜¯å¯ä»¥å…ˆç¿»ä¹¦ï¼ˆ**æ£€ç´¢**ï¼‰ï¼Œæ‰¾åˆ°æœ€ç›¸å…³çš„é‚£å‡ é¡µï¼Œç„¶åç»“åˆä¹¦é‡Œçš„ä¿¡æ¯å’Œä½ è‡ªå·±çš„ç†è§£ï¼ˆ**ç”Ÿæˆ**ï¼‰ï¼Œå†™å‡ºä¸€ä¸ªæœ‰ç†æœ‰æ®ã€å‡ ä¹æ»¡åˆ†çš„ç­”æ¡ˆã€‚

> **ç®€å•è¯´ï¼ŒRAG å°±æ˜¯ä¸€ä¸ªè®© AI åœ¨å›ç­”å‰å…ˆâ€œæŸ¥èµ„æ–™â€çš„æŠ€æœ¯æ¡†æ¶ã€‚å®ƒæŠŠå¤§æ¨¡å‹çš„æ¨ç†èƒ½åŠ›å’Œå¤–éƒ¨çš„ã€é²œæ´»çš„çŸ¥è¯†åº“å·§å¦™åœ°ç»“åˆåœ¨äº†ä¸€èµ·ã€‚**

### ä¸ºä»€ä¹ˆæˆ‘ä»¬éœ€è¦ RAGï¼Ÿæ²»æ²»å¤§æ¨¡å‹çš„â€œå¥å¿˜ç—‡â€å’Œâ€œå¹»æƒ³ç™–â€

å¤§æ¨¡å‹å¤©ç”Ÿå°±æœ‰å‡ ä¸ªè®©äººå¤´ç–¼çš„æ¯›ç—…ï¼š

1. **çŸ¥è¯†æœ‰æ—¶å·®ï¼š** å®ƒä»¬çš„çŸ¥è¯†æ˜¯é™æ€çš„ï¼Œæ°¸è¿œè¿½ä¸ä¸Šç°å®ä¸–ç•Œçš„å˜åŒ–ã€‚
2. **çˆ±è¯´æ¢¦è¯ï¼š** é‡åˆ°çŸ¥è¯†ç›²åŒºï¼Œå®ƒä»¬å€¾å‘äºâ€œåˆ›ä½œâ€ç­”æ¡ˆï¼Œè€Œä¸æ˜¯æ‰¿è®¤â€œæˆ‘ä¸çŸ¥é“â€ã€‚
3. **ä¸æ‡‚è¡Œè¯ï¼š** å¯¹äºå…¬å¸å†…éƒ¨çš„è§„ç« åˆ¶åº¦ã€ç‰¹å®šé¡¹ç›®çš„æŠ€æœ¯æ–‡æ¡£ï¼Œé€šç”¨å¤§æ¨¡å‹å®Œå…¨æ˜¯é—¨å¤–æ±‰ã€‚
4. **è®­ç»ƒå¤ªçƒ§é’±ï¼š** æƒ³è®©æ¨¡å‹å­¦ä¼šæ–°çŸ¥è¯†å°±é‡æ–°è®­ç»ƒä¸€æ¬¡ï¼Ÿé‚£æˆæœ¬ç®€ç›´æ˜¯å¤©æ–‡æ•°å­—ã€‚

RAG å°±åƒä¸€ä¸ªâ€œå¤–æŒ‚â€ï¼Œç”¨æä½çš„æˆæœ¬æ²»å¥½äº†è¿™äº›æ¯›ç—…ï¼Œè®©æ¨¡å‹çš„å›ç­”ä¸ä»…å‡†ç¡®ï¼Œè€Œä¸”æœ‰æºå¯æº¯ã€‚

### RAG çš„ä¸¤æ­¥èµ°â€œå¼€å·â€ç§˜ç±

æ•´ä¸ªâ€œå¼€å·è€ƒè¯•â€çš„è¿‡ç¨‹ï¼ŒRAG åˆ†ä¸¤æ­¥èµ°ï¼Œç®€å•åˆé«˜æ•ˆï¼š

1. **ç¬¬ä¸€æ­¥ï¼šæ£€ç´¢ï¼ˆRetrievalï¼‰â€”â€” å¿«é€Ÿç¿»ä¹¦æ‰¾ç­”æ¡ˆ**
    å½“ç”¨æˆ·æé—®æ—¶ï¼Œç³»ç»Ÿå¹¶ä¸ä¼šç›´æ¥æŠŠé—®é¢˜æ‰”ç»™å¤§æ¨¡å‹ã€‚å®ƒä¼šå…ˆæŠŠé—®é¢˜å˜æˆä¸€ç§æ•°å­¦è¯­è¨€ï¼ˆå‘é‡ï¼‰ï¼Œç„¶ååœ¨æˆ‘ä»¬ç»™å®ƒçš„é‚£æœ¬â€œå‚è€ƒä¹¦â€ï¼ˆçŸ¥è¯†åº“ï¼‰é‡Œï¼Œé£å¿«åœ°æ‰¾åˆ°å†…å®¹æœ€åŒ¹é…çš„å‡ ä¸ªæ®µè½ã€‚

2. **ç¬¬äºŒæ­¥ï¼šç”Ÿæˆï¼ˆGenerationï¼‰â€”â€” ç»“åˆææ–™å†™ç­”æ¡ˆ**
    ç°åœ¨ï¼Œç³»ç»Ÿä¼šæŠŠç”¨æˆ·æœ€åˆçš„é—®é¢˜å’Œä¸Šä¸€æ­¥æ‰¾åˆ°çš„ç›¸å…³æ®µè½â€œæ‰“åŒ…â€ï¼Œä¸€èµ·äº¤ç»™å¤§æ¨¡å‹ï¼Œå¹¶ä¸‹è¾¾æŒ‡ä»¤ï¼šâ€œå˜¿ï¼Œæ ¹æ®è¿™äº›å‚è€ƒææ–™ï¼Œå›ç­”è¿™ä¸ªé—®é¢˜ã€‚â€ å¤§æ¨¡å‹ä¸€çœ‹ï¼Œå‚è€ƒç­”æ¡ˆéƒ½å–‚åˆ°å˜´è¾¹äº†ï¼Œè‡ªç„¶å°±èƒ½ç”Ÿæˆä¸€ä¸ªç²¾å‡†åˆå¯é çš„å›ç­”äº†ã€‚

![RAG](https://www.promptingguide.ai/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Frag.c6528d99.png&w=1920&q=75)

è¿™ä¸ªè¿‡ç¨‹ï¼Œæ˜¯ä¸æ˜¯åƒæäº†æˆ‘ä»¬å†™è®ºæ–‡æ—¶æŸ¥æ‰¾æ–‡çŒ®ã€ç„¶åå¼•ç»æ®å…¸çš„æ ·å­ï¼Ÿ

### RAG vs. å¾®è°ƒ (Fine-tuning)ï¼šå¼€å·è€ƒè¯•è¿˜æ˜¯é¢˜æµ·æˆ˜æœ¯ï¼Ÿ

è¯´åˆ°è®©æ¨¡å‹å­¦æ–°ä¸œè¥¿ï¼Œå¾ˆå¤šäººä¼šæƒ³åˆ°â€œå¾®è°ƒâ€ï¼ˆFine-tuningï¼‰ã€‚è¿™ä¸¤è€…æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ

- **RAG æ˜¯â€œå¼€å·è€ƒè¯•â€**ï¼šå®ƒä¸æ”¹å˜æ¨¡å‹æœ¬èº«ï¼Œè€Œæ˜¯ç»™å®ƒä¸€ä¸ªå¤–éƒ¨çš„ã€å¯ä»¥éšæ—¶æ›´æ–°çš„çŸ¥è¯†åº“ã€‚çŸ¥è¯†æ›´æ–°å¿«ï¼Œæˆæœ¬ä½ï¼Œè€Œä¸”æœ‰æ®å¯æŸ¥ï¼Œç‰¹åˆ«é€‚åˆé—®ç­”ã€å®¢æœè¿™ç±»éœ€è¦äº‹å®æ”¯æ’‘çš„åœºæ™¯ã€‚
- **å¾®è°ƒæ˜¯â€œé¢˜æµ·æˆ˜æœ¯â€**ï¼šå®ƒæ˜¯ç”¨ç‰¹å®šçš„æ•°æ®é›†å»ç»§ç»­è®­ç»ƒæ¨¡å‹ï¼Œæ”¹å˜æ¨¡å‹å†…éƒ¨çš„å‚æ•°ã€‚è¿™æ›´åƒæ˜¯è®©æ¨¡å‹é€šè¿‡å¤§é‡åˆ·é¢˜ï¼Œå­¦ä¼šæŸç§ç‰¹å®šçš„â€œè§£é¢˜é£æ ¼â€æˆ–â€œè¯­æ°”â€ï¼Œæ¯”å¦‚æ¨¡ä»¿èå£«æ¯”äºšå†™ä½œã€æˆ–è€…å­¦ä¹ ä½ çš„ç¼–ç¨‹é£æ ¼ã€‚å®ƒå­¦åˆ°çš„æ˜¯ä¸€ç§â€œæ„Ÿè§‰â€ï¼ŒçŸ¥è¯†æœ¬èº«è¿˜æ˜¯é™æ€çš„ã€‚

> **å°ç»“ä¸€ä¸‹ï¼š** RAG å’Œå¾®è°ƒä¸æ˜¯æ•Œäººï¼Œè€Œæ˜¯å¥½æ­æ¡£ã€‚ä½ å¯ä»¥å…ˆç”¨å¾®è°ƒæŠŠæ¨¡å‹çš„â€œæ€§æ ¼â€è°ƒæ•™å¥½ï¼Œå†ç”¨ RAG ç»™å®ƒæ¥ä¸Šä¸€ä¸ªå®æ—¶æ›´æ–°çš„â€œå¤–è„‘â€ï¼Œæ•ˆæœæ‹”ç¾¤ï¼

## äºŒã€åŠ¨æ‰‹ï¼æ‰“é€ ä½ çš„ç§äººçŸ¥è¯†é—®ç­”æœºå™¨äºº

ç†è®ºå¬ç€çˆ½ï¼Œä¸å¦‚äº²æ‰‹æä¸€æŠŠã€‚ä¸‹é¢ï¼Œæˆ‘ä»¬å°±ç”¨ Python å’Œ OpenAI çš„ APIï¼Œä¸€æ­¥æ­¥æ­ä¸€ä¸ªèƒ½å›ç­”ä½ æœ¬åœ°æ–‡ä»¶å†…å®¹çš„ RAG åº”ç”¨ã€‚

### å‡†å¤‡å·¥ä½œï¼šé…å¥½â€œå…µå™¨åº“â€

é¦–å…ˆï¼Œå¾—æŠŠå®¶ä¼™ä»€å„¿è£…å¥½ã€‚æˆ‘ä»¬ä¼šç”¨åˆ° LangChain æ¡†æ¶ï¼Œå®ƒèƒ½è®©æ•´ä¸ªè¿‡ç¨‹å˜å¾—åƒæ­ç§¯æœ¨ä¸€æ ·ç®€å•ã€‚

```bash
pip install openai langchain tiktoken faiss-cpu langchain_community langchain_openai python-dotenv
```

è£…å¥½åï¼Œåœ¨ä½ çš„é¡¹ç›®æ–‡ä»¶å¤¹é‡Œå»ºä¸€ä¸ª `.env` æ–‡ä»¶ï¼ŒæŠŠä½ çš„ OpenAI API å¯†é’¥æ”¾è¿›å»ï¼Œåƒè¿™æ ·ï¼š

```env # .env æ–‡ä»¶
OPENAI_API_KEY="sk-ä½ çš„å¯†é’¥"
```

### æ ¸å¿ƒä¸‰éƒ¨æ›²ï¼šåŠ è½½ã€å‘é‡åŒ–ã€é—®ç­”

æ•´ä¸ªè¿‡ç¨‹è·Ÿæˆ‘ä»¬å‰é¢è®²çš„åŸç†å®Œå…¨å¯¹åº”ï¼š

1. **åŠ è½½ä¸åˆ‡åˆ† (Load & Split):** æŠŠæˆ‘ä»¬é‚£æœ¬â€œå‚è€ƒä¹¦â€ï¼ˆæ¯”å¦‚ä¸€ä¸ª .txt æ–‡ä»¶ï¼‰è¯»è¿›æ¥ï¼Œå¹¶åˆ‡æˆä¸€å°æ®µä¸€å°æ®µï¼Œæ–¹ä¾¿åé¢ç²¾å‡†æŸ¥æ‰¾ã€‚
2. **å­˜å‚¨ä¸å‘é‡åŒ– (Store & Embed):** æŠŠæ¯ä¸€å°æ®µæ–‡å­—éƒ½å˜æˆä¸€ä¸²æ•°å­—ï¼ˆå‘é‡ï¼‰ï¼Œå­˜è¿›ä¸€ä¸ªå«â€œå‘é‡æ•°æ®åº“â€çš„åœ°æ–¹ã€‚è¿™æ­¥å°±ç›¸å½“äºç»™ä¹¦çš„æ¯ä¸€é¡µå†…å®¹éƒ½è´´ä¸Šä¸€ä¸ªç²¾å‡†çš„â€œæ•°å­—æŒ‡çº¹â€ã€‚
3. **æ£€ç´¢ä¸ç”Ÿæˆ (Retrieve & Generate):** å½“ä½ æé—®æ—¶ï¼Œç³»ç»Ÿä¼šæŠŠä½ é—®é¢˜çš„â€œæ•°å­—æŒ‡çº¹â€å’Œæ•°æ®åº“é‡Œæ‰€æœ‰æ®µè½çš„â€œæŒ‡çº¹â€åšå¯¹æ¯”ï¼Œæ‰¾å‡ºæœ€åƒçš„å‡ ä¸ªï¼Œç„¶åè¿åŒé—®é¢˜ä¸€èµ·æ‰“åŒ…å‘ç»™å¤§æ¨¡å‹ï¼Œè®©å®ƒç”Ÿæˆæœ€ç»ˆç­”æ¡ˆã€‚

### ç¬¬1æ­¥ï¼šå‡†å¤‡â€œå‚è€ƒä¹¦â€å¹¶åˆ‡åˆ†

å…ˆåˆ›å»ºä¸€ä¸ª `my_knowledge.txt` æ–‡ä»¶ï¼Œéšä¾¿å†™ç‚¹ä»€ä¹ˆï¼Œè¿™å°±æ˜¯æˆ‘ä»¬çš„çŸ¥è¯†åº“ã€‚

```text # my_knowledge.txt
RAGï¼Œå…¨ç§°æ˜¯æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆRetrieval-Augmented Generationï¼‰ï¼Œæ˜¯ä¸€ç§èƒ½è®©å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰å¼•ç”¨å¤–éƒ¨çŸ¥è¯†åº“æ¥ç”Ÿæˆå›ç­”çš„æŠ€æœ¯ã€‚
å®ƒçš„æ ¸å¿ƒæ€æƒ³åˆ†ä¸ºä¸¤ä¸ªæ­¥éª¤ï¼šæ£€ç´¢ï¼ˆRetrievalï¼‰å’Œç”Ÿæˆï¼ˆGenerationï¼‰ã€‚
åœ¨æ£€ç´¢é˜¶æ®µï¼Œç³»ç»Ÿä¼šæ ¹æ®ç”¨æˆ·çš„é—®é¢˜ï¼Œä»çŸ¥è¯†åº“ä¸­æ‰¾åˆ°æœ€ç›¸å…³çš„æ–‡æœ¬ç‰‡æ®µã€‚
åœ¨ç”Ÿæˆé˜¶æ®µï¼ŒLLMä¼šç»“åˆåŸå§‹é—®é¢˜å’Œæ£€ç´¢åˆ°çš„æ–‡æœ¬ç‰‡æ®µï¼Œç”Ÿæˆä¸€ä¸ªå†…å®¹ä¸°å¯Œä¸”å‡†ç¡®çš„å›ç­”ã€‚
ä¸å¾®è°ƒï¼ˆFine-tuningï¼‰ç›¸æ¯”ï¼ŒRAGåœ¨å¤„ç†éœ€è¦å®æ—¶æ›´æ–°çŸ¥è¯†æˆ–äº‹å®æ€§å¾ˆå¼ºçš„ä»»åŠ¡æ—¶ï¼Œæ›´å…·ä¼˜åŠ¿å’Œæˆæœ¬æ•ˆç›Šã€‚
```

æ¥ç€ï¼Œç”¨ Python æŠŠå®ƒåŠ è½½è¿›æ¥å¹¶åˆ‡å—ã€‚

```python # main.py
import os
from dotenv import load_dotenv
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import CharacterTextSplitter

# è®©ç¨‹åºèƒ½è¯»åˆ° .env æ–‡ä»¶é‡Œçš„å¯†é’¥
load_dotenv()

# 1. åŠ è½½æ–‡æ¡£
loader = TextLoader("./my_knowledge.txt", encoding="utf-8")
documents = loader.load()

# 2. åˆ‡åˆ†æ–‡æ¡£
text_splitter = CharacterTextSplitter(
    separator="\n",
    chunk_size=200,     # æ¯ä¸ªå—çš„å¤§å°
    chunk_overlap=50,   # å—ä¹‹é—´çš„é‡å ï¼Œé˜²æ­¢è¯­ä¹‰å‰²è£‚
)
docs = text_splitter.split_documents(documents)

print(f"çŸ¥è¯†åº“è¢«åˆ‡åˆ†æˆäº† {len(docs)} ä¸ªç‰‡æ®µã€‚")
```

> **ä¸ºä»€ä¹ˆè¦åˆ‡åˆ†ï¼Ÿ**
> ä½ æ€»ä¸èƒ½æŠŠä¸€æ•´æœ¬ä¹¦éƒ½æ‰”ç»™å¤§æ¨¡å‹è®©å®ƒè‡ªå·±è¯»å§ï¼Ÿä¸Šä¸‹æ–‡çª—å£æœ‰é™ï¼Œè€Œä¸”æ•ˆç‡å¤ªä½ã€‚åˆ‡æˆå°å—ï¼Œæ‰èƒ½å®ç°â€œç²¾å‡†æŠ•å–‚â€ã€‚

### ç¬¬2æ­¥ï¼šç»™çŸ¥è¯†æ‰“ä¸Šâ€œæ•°å­—æŒ‡çº¹â€å¹¶å­˜èµ·æ¥

è¿™æ˜¯ RAG çš„é­”æ³•æ ¸å¿ƒã€‚æˆ‘ä»¬ç”¨ OpenAI çš„æ¨¡å‹æŠŠæ–‡æœ¬å—å˜æˆå‘é‡ï¼Œç„¶åç”¨ FAISS è¿™ä¸ªåº“æŠŠå®ƒä»¬å­˜åœ¨æœ¬åœ°ã€‚

```python # (ç»­) main.py
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS

# åˆå§‹åŒ–ç”¨æ¥ç”Ÿæˆâ€œæ•°å­—æŒ‡çº¹â€çš„æ¨¡å‹
embeddings_model = OpenAIEmbeddings()

# åˆ›å»ºå‘é‡æ•°æ®åº“ï¼Œè¿™ä¸€æ­¥ä¼šæŠŠæ‰€æœ‰æ–‡æ¡£ç‰‡æ®µå¤„ç†å¹¶å­˜å‚¨
print("æ­£åœ¨ä¸ºçŸ¥è¯†åº“åˆ›å»ºç´¢å¼•...")
db = FAISS.from_documents(docs, embeddings_model)
print("ç´¢å¼•åˆ›å»ºå®Œæˆï¼")

# æŠŠå»ºå¥½çš„ç´¢å¼•å­˜åˆ°æœ¬åœ°ï¼Œä¸‹æ¬¡å°±ä¸ç”¨é‡æ–°å»ºäº†
db.save_local("faiss_index")
```

è¿è¡Œå®Œï¼Œä½ ä¼šçœ‹åˆ°å¤šäº†ä¸€ä¸ª `faiss_index` æ–‡ä»¶å¤¹ï¼Œæ­å–œä½ ï¼Œä½ çš„æœ¬åœ°çŸ¥è¯†å¤§è„‘å·²ç»å»ºå¥½äº†ï¼

### ç¬¬3æ­¥ï¼šè§è¯å¥‡è¿¹çš„æ—¶åˆ»â€”â€”å¼€å§‹æé—®

ä¸‡äº‹ä¿±å¤‡ï¼Œæˆ‘ä»¬æ¥åˆ›å»ºä¸€ä¸ªå®Œæ•´çš„é—®ç­”é“¾ï¼Œè®©å®ƒè‡ªåŠ¨å®Œæˆæ£€ç´¢å’Œç”Ÿæˆçš„æ‰€æœ‰å·¥ä½œã€‚

```python # (å®Œæ•´ä»£ç ) main.py
import os
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.document_loaders import TextLoader
from langchain_text_splitters import CharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.chains import create_retrieval_chain
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain_core.prompts import ChatPromptTemplate

load_dotenv()

# --- æ™ºèƒ½åŠ è½½ç´¢å¼• ---
try:
    print("æ­£åœ¨ä»æœ¬åœ°åŠ è½½ç´¢å¼•...")
    db = FAISS.load_local("faiss_index", OpenAIEmbeddings(), allow_dangerous_deserialization=True)
except Exception:
    print("ç´¢å¼•æœªæ‰¾åˆ°ï¼Œå¼€å§‹åˆ›å»ºæ–°ç´¢å¼•...")
    loader = TextLoader("./my_knowledge.txt", encoding="utf-8")
    documents = loader.load()
    text_splitter = CharacterTextSplitter(chunk_size=200, chunk_overlap=50)
    docs = text_splitter.split_documents(documents)
    embeddings_model = OpenAIEmbeddings()
    db = FAISS.from_documents(docs, embeddings_model)
    db.save_local("faiss_index")

# --- RAG æ ¸å¿ƒé“¾ ---
retriever = db.as_retriever()
llm = ChatOpenAI(model="gpt-3.5-turbo")

# è¿™é‡Œæ˜¯å…³é”®ï¼æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªæ¨¡æ¿ï¼Œå‘Šè¯‰æ¨¡å‹ä½ æ˜¯ä¸€ä¸ªåªä¾èµ–å‚è€ƒèµ„æ–™çš„ä¸¥è°¨çš„å›ç­”è€…
prompt = ChatPromptTemplate.from_template("""
ä½ æ˜¯ä¸€ä¸ªä¸¥è°¨çš„é—®ç­”æœºå™¨äººã€‚è¯·åªæ ¹æ®ä¸‹é¢æä¾›çš„â€œå‚è€ƒèµ„æ–™â€æ¥å›ç­”é—®é¢˜ï¼Œä¸è¦è‡ªå·±ç¼–é€ ç­”æ¡ˆã€‚

<context>
{context}
</context>

é—®é¢˜: {input}
""")

document_chain = create_stuff_documents_chain(llm, prompt)
retrieval_chain = create_retrieval_chain(retriever, document_chain)

# --- å¼€å§‹æé—® ---
print("\nçŸ¥è¯†åº“å·²å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥å¼€å§‹æé—®äº†ï¼")

def ask_question(question):
    response = retrieval_chain.invoke({"input": question})
    print("="*30)
    print(f"ğŸ¤” ä½ çš„é—®é¢˜: {question}")
    print(f"ğŸ¤– æˆ‘çš„å›ç­”: {response['answer']}")
    print("---")
    # print("ğŸ” æˆ‘å‚è€ƒçš„èµ„æ–™ç‰‡æ®µ:")
    # for i, doc in enumerate(response["context"]):
    #     print(f"  - {doc.page_content.strip()}")
    print("="*30)

ask_question("RAG çš„æ ¸å¿ƒæ€æƒ³æ˜¯ä»€ä¹ˆï¼Ÿ")
ask_question("RAG å’Œå¾®è°ƒæœ‰å•¥ä¸ä¸€æ ·ï¼Ÿ")
ask_question("ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·?")
```

**çœ‹çœ‹ç»“æœï¼š**

- å‰ä¸¤ä¸ªé—®é¢˜ï¼Œå®ƒä¼šåƒä¸ªå­¦éœ¸ä¸€æ ·ï¼Œæ ¹æ®æˆ‘ä»¬æŠ•å–‚çš„ `my_knowledge.txt` ç»™å‡ºç²¾å‡†çš„ç­”æ¡ˆã€‚
- å½“ä½ é—®å®ƒâ€œä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·â€æ—¶ï¼Œå¥‡å¦™çš„äº‹æƒ…å‘ç”Ÿäº†ï¼ç”±äºçŸ¥è¯†åº“é‡Œæ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œå¹¶ä¸”æˆ‘ä»¬çš„ Prompt ä¸¥æ ¼é™åˆ¶äº†å®ƒï¼Œå®ƒä¼šå¾ˆè€å®åœ°å‘Šè¯‰ä½ â€œæ ¹æ®æä¾›çš„èµ„æ–™æˆ‘æ— æ³•å›ç­”â€ï¼Œ**ä»è€Œå®Œç¾åœ°é¿å…äº†â€œå¹»è§‰â€**ã€‚

## ä¸‰ã€æ€»ç»“ï¼šä½ çš„ AIï¼Œä»æ­¤æœ‰äº†â€œè®°å¿†â€

ä»Šå¤©ï¼Œæˆ‘ä»¬ä¸ä»…ææ‡‚äº† RAG è¿™ä¸ªé…·ç‚«çš„æŠ€æœ¯ï¼Œè¿˜äº²æ‰‹æ‰“é€ äº†ä¸€ä¸ªè¿·ä½ ç‰ˆçš„çŸ¥è¯†åº“é—®ç­”æœºå™¨äººã€‚

RAG å°±åƒæ˜¯ç»™å¤§æ¨¡å‹è£…ä¸Šäº†ä¸€ä¸ªå¯æ’æ‹”ã€å¯å®æ—¶æ›´æ–°çš„â€œå¤–æ¥ç¡¬ç›˜â€ã€‚æœ‰äº†å®ƒï¼Œä½ çš„ AI ä¸å†æ˜¯ä¸€ä¸ªåªä¼šèƒŒä¹¦çš„â€œä¹¦å‘†å­â€ï¼Œè€Œæ˜¯ä¸€ä¸ªèƒ½éšæ—¶æŸ¥é˜…æœ€æ–°èµ„æ–™çš„â€œä¸“å®¶â€ã€‚

è¿™åªæ˜¯ä¸€ä¸ªå¼€å§‹ã€‚ä½ å¯ä»¥æŠŠçŸ¥è¯†æºæ¢æˆ PDFã€ç½‘é¡µã€å…¬å¸çš„æ•°æ®åº“... å»è§£é”å„ç§æœ‰æ„æ€çš„åº”ç”¨ï¼š

- **7x24 å°æ—¶çš„æ™ºèƒ½å®¢æœ**
- **åªå±äºä½ çš„ä¸ªäººçŸ¥è¯†ç®¡å®¶**
- **å¸®ä½ è¯»è®ºæ–‡ã€çœ‹æŠ¥å‘Šçš„ç§‘ç ”åŠ©ç†**

å½“ç„¶ï¼ŒçœŸæ­£å·¥ä¸šçº§çš„ RAG ç³»ç»Ÿä¼šæ›´å¤æ‚ï¼Œéœ€è¦è€ƒè™‘æ–‡æ¡£åˆ‡åˆ†çš„è‰ºæœ¯ã€æ›´ç‰›çš„æ£€ç´¢ç®—æ³•ç­‰ç­‰ã€‚ä½†åˆ«æ€•ï¼Œä½ å·²ç»æ¨å¼€äº†è¿™æ‰‡å¤§é—¨ï¼Œæœªæ¥çš„ä¸–ç•Œï¼Œæ­£ç­‰ç€ä½ ç”¨ RAG å»åˆ›é€ ï¼

## å‚è€ƒ

- [LangChain å®˜æ–¹æ–‡æ¡£](https://python.langchain.com/docs/get_started/introduction)
- [OpenAI API æ–‡æ¡£](https://platform.openai.com/docs/introduction)
- [FAISS: A library for efficient similarity search](https://github.com/facebookresearch/faiss)
